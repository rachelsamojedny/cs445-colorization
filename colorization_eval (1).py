# -*- coding: utf-8 -*-
"""colorization-eval.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S9rCG2JUrkUunP7NZQ04-3mbOlUaF5K7
"""

#evaluation
import torch
import numpy as np
import torchvision.models as models

def evaluate(model, test_loader, criterion):
    vgg = models.vgg19(pretrained=True).eval().to(model.device)
    correct_fake = 0
    total = 0
    best_accuracy = 0
    best_idx = 0

    with torch.no_grad():
        for i, batch in enumerate(test_loader):
            gray_images = batch['input']
            color_images = batch['output']

            colorized_images = model(gray_images) #run model to get colorized images (TODO; make sure this is right call)
            outputs_fake = vgg(colorized_images) #run our fake colorized images thru VGG and see the scores
            outputs_real = vgg(color_images) #get the real labels using the output
            _, predicted_fake = torch.max(outputs_fake.data, 1) #take the scores and get the prediction (which label has highest score)
            _, predicted_real = torch.max(outputs_real.data, 1)
            current_correct += (predicted_fake == predicted_real).sum().item() #how many predictions are correct
            correct_fake += current_correct
            current_total = labels.size(0)
            total += current_total

            if (current_correct / current_total) > best_accuracy:
              best_accuracy = current_correct / current_total
              best_idx = i
   #TODO: display the best accuracy depending on how the color images are input to this, i kept track of index for now (such as if returned in tensor or single image)
   #just use plt.imshow with the index as needed



    accuracy = 100 * correct_fake / total

    print(f'Accuracy on fake colorized images from model: {accuracy}%') #total accuracy of model


    return accuracy_fake